{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18 Transfer Learning: Who's that Pokémon?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from dataset_class import PokemonImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_number</th>\n",
       "      <th>gen</th>\n",
       "      <th>english_name</th>\n",
       "      <th>japanese_name</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>secondary_type</th>\n",
       "      <th>classification</th>\n",
       "      <th>percent_male</th>\n",
       "      <th>percent_female</th>\n",
       "      <th>height_m</th>\n",
       "      <th>...</th>\n",
       "      <th>evochain_2</th>\n",
       "      <th>evochain_3</th>\n",
       "      <th>evochain_4</th>\n",
       "      <th>evochain_5</th>\n",
       "      <th>evochain_6</th>\n",
       "      <th>gigantamax</th>\n",
       "      <th>mega_evolution</th>\n",
       "      <th>mega_evolution_alt</th>\n",
       "      <th>description</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>bulbasaur</td>\n",
       "      <td>Fushigidane</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>Seed Pokémon</td>\n",
       "      <td>88.14</td>\n",
       "      <td>11.86</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Level</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There is a plant seed on its back right from t...</td>\n",
       "      <td>pokemon_images/Bulbasaur.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>ivysaur</td>\n",
       "      <td>Fushigisou</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>Seed Pokémon</td>\n",
       "      <td>88.14</td>\n",
       "      <td>11.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Level</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the bulb on its back grows large, it appe...</td>\n",
       "      <td>pokemon_images/Ivysaur.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>venusaur</td>\n",
       "      <td>Fushigibana</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>Seed Pokémon</td>\n",
       "      <td>88.14</td>\n",
       "      <td>11.86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Level</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gigantamax Venusaur</td>\n",
       "      <td>Mega Venusaur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Its plant blooms when it is absorbing solar en...</td>\n",
       "      <td>pokemon_images/Venusaur.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>charmander</td>\n",
       "      <td>Hitokage</td>\n",
       "      <td>fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lizard Pokémon</td>\n",
       "      <td>88.14</td>\n",
       "      <td>11.86</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Level</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It has a preference for hot things. When it ra...</td>\n",
       "      <td>pokemon_images/Charmander.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>charmeleon</td>\n",
       "      <td>Lizardo</td>\n",
       "      <td>fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flame Pokémon</td>\n",
       "      <td>88.14</td>\n",
       "      <td>11.86</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Level</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It has a barbaric nature. In battle, it whips ...</td>\n",
       "      <td>pokemon_images/Charmeleon.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_number gen english_name japanese_name primary_type secondary_type  \\\n",
       "0                1   I    bulbasaur   Fushigidane        grass         poison   \n",
       "1                2   I      ivysaur    Fushigisou        grass         poison   \n",
       "2                3   I     venusaur   Fushigibana        grass         poison   \n",
       "3                4   I   charmander      Hitokage         fire            NaN   \n",
       "4                5   I   charmeleon       Lizardo         fire            NaN   \n",
       "\n",
       "   classification percent_male percent_female  height_m  ...  evochain_2  \\\n",
       "0    Seed Pokémon        88.14          11.86       0.7  ...     Ivysaur   \n",
       "1    Seed Pokémon        88.14          11.86       1.0  ...     Ivysaur   \n",
       "2    Seed Pokémon        88.14          11.86       2.0  ...     Ivysaur   \n",
       "3  Lizard Pokémon        88.14          11.86       0.6  ...  Charmeleon   \n",
       "4   Flame Pokémon        88.14          11.86       1.1  ...  Charmeleon   \n",
       "\n",
       "  evochain_3  evochain_4  evochain_5  evochain_6           gigantamax  \\\n",
       "0     Level     Venusaur         NaN         NaN                  NaN   \n",
       "1     Level     Venusaur         NaN         NaN                  NaN   \n",
       "2     Level     Venusaur         NaN         NaN  Gigantamax Venusaur   \n",
       "3     Level    Charizard         NaN         NaN                  NaN   \n",
       "4     Level    Charizard         NaN         NaN                  NaN   \n",
       "\n",
       "   mega_evolution  mega_evolution_alt  \\\n",
       "0             NaN                 NaN   \n",
       "1             NaN                 NaN   \n",
       "2   Mega Venusaur                 NaN   \n",
       "3             NaN                 NaN   \n",
       "4             NaN                 NaN   \n",
       "\n",
       "                                         description  \\\n",
       "0  There is a plant seed on its back right from t...   \n",
       "1  When the bulb on its back grows large, it appe...   \n",
       "2  Its plant blooms when it is absorbing solar en...   \n",
       "3  It has a preference for hot things. When it ra...   \n",
       "4  It has a barbaric nature. In battle, it whips ...   \n",
       "\n",
       "                      image_path  \n",
       "0   pokemon_images/Bulbasaur.jpg  \n",
       "1     pokemon_images/Ivysaur.jpg  \n",
       "2    pokemon_images/Venusaur.jpg  \n",
       "3  pokemon_images/Charmander.jpg  \n",
       "4  pokemon_images/Charmeleon.jpg  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pokemon.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying a Pokémon's Primary type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['image_path', 'primary_type']) \n",
    "df['main_type'] = df['primary_type'].str.strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot perform 'rand_' with a dtyped [object] array and scalar of type [bool]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:362\u001b[39m, in \u001b[36mna_logical_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    354\u001b[39m     \u001b[38;5;66;03m# For exposition, write:\u001b[39;00m\n\u001b[32m    355\u001b[39m     \u001b[38;5;66;03m#  yarr = isinstance(y, np.ndarray)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    360\u001b[39m     \u001b[38;5;66;03m# Then Cases where this goes through without raising include:\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;66;03m#  (xint or xbool) and (yint or bool)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     result = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/roperator.py:54\u001b[39m, in \u001b[36mrand_\u001b[39m\u001b[34m(left, right)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrand_\u001b[39m(left, right):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mand_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for &: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:376\u001b[39m, in \u001b[36mna_logical_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    378\u001b[39m     \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[32m    379\u001b[39m     \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     \u001b[38;5;167;01mNotImplementedError\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mops.pyx:210\u001b[39m, in \u001b[36mpandas._libs.ops.scalar_binop\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/roperator.py:54\u001b[39m, in \u001b[36mrand_\u001b[39m\u001b[34m(left, right)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrand_\u001b[39m(left, right):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mand_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for &: 'bool' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m filt = df[\u001b[33m\"\u001b[39m\u001b[33mmain_type\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrass\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmain_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m\"\u001b[39m\u001b[33mfire\u001b[39m\u001b[33m\"\u001b[39m & df[\u001b[33m\"\u001b[39m\u001b[33mmain_type\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mwater\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m df = df[filt]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/arraylike.py:74\u001b[39m, in \u001b[36mOpsMixin.__rand__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__rand__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__rand__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_logical_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/series.py:6130\u001b[39m, in \u001b[36mSeries._logical_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6127\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:454\u001b[39m, in \u001b[36mlogical_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m     \u001b[38;5;66;03m# i.e. scalar\u001b[39;00m\n\u001b[32m    452\u001b[39m     is_other_int_dtype = lib.is_integer(rvalues)\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m res_values = \u001b[43mna_logical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# For int vs int `^`, `|`, `&` are bitwise operators and return\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m#   integer dtypes.  Otherwise these are boolean ops\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (left.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_other_int_dtype):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:385\u001b[39m, in \u001b[36mna_logical_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    377\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    378\u001b[39m             \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[32m    379\u001b[39m             \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m             \u001b[38;5;167;01mNotImplementedError\u001b[39;00m,\n\u001b[32m    383\u001b[39m         ) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    384\u001b[39m             typ = \u001b[38;5;28mtype\u001b[39m(y).\u001b[34m__name__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    386\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot perform \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m with a dtyped [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] array \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    387\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand scalar of type [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    388\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\u001b[31mTypeError\u001b[39m: Cannot perform 'rand_' with a dtyped [object] array and scalar of type [bool]"
     ]
    }
   ],
   "source": [
    "filt = (df[\"main_type\"] == \"grass\") & (df[\"main_type\"] == \"fire\") & (df[\"main_type\"] == \"water\")\n",
    "df = df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['grass', 'fire', 'water', 'bug', 'normal', 'poison', 'electric', 'ground', 'fairy', 'fighting', 'psychic', 'rock', 'ghost', 'ice', 'dragon', 'dark', 'steel', 'flying']\n"
     ]
    }
   ],
   "source": [
    "type_names = df['main_type'].unique().tolist()\n",
    "print(\"Classes:\", type_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (Encoded): [9, 6, 17, 0, 12, 13, 3, 10, 4, 5, 14, 15, 8, 11, 2, 1, 16, 7]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['encoded_type'] = label_encoder.fit_transform(df['main_type'])\n",
    "type_encoded = df['encoded_type'].unique().tolist()\n",
    "print(\"Classes (Encoded):\", type_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes:  18\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(type_encoded)\n",
    "print(\"Number of Classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, \n",
    "                                    stratify=df['encoded_type'], \n",
    "                                    random_state = 13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PokemonImages(df = train_df, label = \"encoded_type\", transform=transforms)\n",
    "val_dataset = PokemonImages(df = val_df, label = \"encoded_type\", transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = models.resnet50(weights= models.ResNet50_Weights.DEFAULT)\n",
    "resnet50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezes the whole model\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Reseting the Final Layer and param.requires_grad = True by default \n",
    "# Final Layer is resnet18.fc \n",
    "final_layer_features = resnet50.fc.in_features\n",
    "\n",
    "# Outputting new number of Classes\n",
    "resnet50.fc = nn.Linear(final_layer_features, num_classes)\n",
    "\n",
    "# Cross Entropy Loss for Multiple Classes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizing all Parameters in the final linear layer using SGD\n",
    "optimizer = optim.SGD(resnet50.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decrease Learning Rate by a factor of 0.1 every 7 epochs\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.8883 Acc: 0.0572\n",
      "val Loss: 2.8378 Acc: 0.1278\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 2.7757 Acc: 0.1506\n",
      "val Loss: 2.7459 Acc: 0.1667\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 2.6904 Acc: 0.1757\n",
      "val Loss: 2.6943 Acc: 0.1889\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 2.6271 Acc: 0.1980\n",
      "val Loss: 2.6536 Acc: 0.2278\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 2.5831 Acc: 0.2273\n",
      "val Loss: 2.6221 Acc: 0.2444\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 2.5368 Acc: 0.2552\n",
      "val Loss: 2.6004 Acc: 0.2556\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 2.4895 Acc: 0.2762\n",
      "val Loss: 2.5738 Acc: 0.2444\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 2.4681 Acc: 0.2664\n",
      "val Loss: 2.5712 Acc: 0.2667\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 2.4651 Acc: 0.2845\n",
      "val Loss: 2.5677 Acc: 0.2667\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 2.4561 Acc: 0.2943\n",
      "val Loss: 2.5692 Acc: 0.2556\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 2.4591 Acc: 0.2887\n",
      "val Loss: 2.5653 Acc: 0.2722\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 2.4513 Acc: 0.2873\n",
      "val Loss: 2.5601 Acc: 0.2833\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 2.4460 Acc: 0.2831\n",
      "val Loss: 2.5608 Acc: 0.2778\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 2.4421 Acc: 0.2915\n",
      "val Loss: 2.5601 Acc: 0.2833\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 2.4409 Acc: 0.2915\n",
      "val Loss: 2.5546 Acc: 0.2889\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 2.4406 Acc: 0.2999\n",
      "val Loss: 2.5546 Acc: 0.2833\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 2.4387 Acc: 0.2929\n",
      "val Loss: 2.5592 Acc: 0.2833\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 2.4414 Acc: 0.2985\n",
      "val Loss: 2.5546 Acc: 0.2889\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 2.4381 Acc: 0.2887\n",
      "val Loss: 2.5567 Acc: 0.2889\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 2.4402 Acc: 0.2999\n",
      "val Loss: 2.5587 Acc: 0.2833\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 2.4394 Acc: 0.3082\n",
      "val Loss: 2.5560 Acc: 0.2889\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 2.4429 Acc: 0.3026\n",
      "val Loss: 2.5588 Acc: 0.2833\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 2.4383 Acc: 0.2985\n",
      "val Loss: 2.5565 Acc: 0.2889\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 2.4314 Acc: 0.2999\n",
      "val Loss: 2.5649 Acc: 0.2778\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 2.4319 Acc: 0.2985\n",
      "val Loss: 2.5608 Acc: 0.2889\n",
      "\n",
      "Training complete in 39m 16s\n",
      "Best val Acc: 0.288889\n"
     ]
    }
   ],
   "source": [
    "final_model = train_model(resnet50, criterion, optimizer,\n",
    "                         lr_scheduler, num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
